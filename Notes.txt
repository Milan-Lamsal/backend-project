                                            PROJECT SETUP 

                                              A. Basic Setup  

1. When storing images via a third-party service like AWS, Azure, or Cloudinary, the typical approach involves temporarily saving uploaded photos and videos on your server. This ensures that if a user's connection is lost during the upload process, the files are still retained. Once successfully received, the files are then uploaded to Cloudinary (or another cloud provider) using a designated process. Some companies choose to upload files directly to Cloudinary without temporary local storage, depending on their standards and requirements.

2. In Git, folders are not tracked directly—only files are. If you create a folder and add an empty subfolder inside it, Git will not recognize or track those folders unless they contain at least one file. This means an empty subfolder serves no purpose in Git since it won’t be included in version control. If you need Git to track an empty folder, a common practice is to add a placeholder file (like .gitkeep). and it should be under the subfolder

3. .gitignore is used to exclude sensitive files and other unnecessary files from being tracked by Git. This includes API keys, configuration files, environment variables, and other confidential data that should not be pushed to a remote repository for security reasons (.gitignore generator-https://mrkandreev.name/snippets/gitignore-generator/#Node)-Using a .gitignore generator saves time and ensures you don’t accidentally commit unnecessary or sensitive files.Different technologies (like Node.js, Python, or React) have their own sets of files that should be ignored, such as: Node.js projects: node_modules/, .env, .DS_Store, and dist/. , React projects: build/, .env, and .next/ (for Next.js).

4. .env files are used to store environment variables, such as API keys, database credentials, and other sensitive information. When deploying to production, these environment variables should not be stored in the source code but should be set up in the server or cloud provider (e.g., AWS, DigitalOcean). This ensures security by keeping sensitive data outside the codebase.

Modern version control platforms like GitHub now warn users if they attempt to push .env files, helping prevent accidental exposure of sensitive information."

5. src/ is a common directory used to store source files in a project. If you are using Git Bash( Best if you’re familiar with Linux/macOS commands and working with Git.) and run the following command inside your project folder:
cd src && touch app.js constants.js index.js
This will navigate to the src/ directory (if it exists) and create three empty files: app.js, constants.js, and index.js."

6. Package.json -> How to open using script also in JavaScript there is two kind of syntax for import one is(CommonJS (CJS)) and ES Modules (ESM), for this project gonna use Module so that there will be consistent for that "type": "module" 
whenever you change the file the server need to be start or stop for reloading or seeing that changes, so to handle that (newly update in Node js --watch to handle that problem) but in the production grade it hasn't been that used so people use the utiliy called (nodemon)-https://www.npmjs.com/package/nodemon (what it does is)- whenever you file is save it restart the server that all it does.

7. Difference in dev dependency( These are packages needed only during the development phase. They are not required in production. These packages are typically used for tasks like testing, building, or development tools. for example nodemon ) and dependency(These are packages that your application needs to run in both development and production environments. They are required for the application to function properly. for example : express, mongoose ) and if its npm i nodemon then it will install in dependency so nned to install nodemon as a development dependency as npm install --save-dev nodemon  or npm i -D nodemon 

8. In the scripts section of package.json, you can create custom commands to run specific tasks. Instead of using the default test command, you can add a dev command to automatically restart your server using nodemon whenever you make changes to your files. we use "dev": "nodemon src/index.js" -> this says nodemon whenever I make some changes in the file then you restart the server after typing [npm start dev]

9. .env and type:module they don't get along so you can't easily import ES6 import 'dotenv/config' you need to use require('dotenv').config() [https://www.npmjs.com/package/dotenv]

====================================================================================================================
                           B. Professional Structure for Project                                                 

10 . Basic command : ls(to list content  ) , cd .. (to go one step back to the parent directory ) cd src (this will move you to src directory if it exist ), mkdir(to make a folder)

11. controllers -> majorly functionality, db -> how to connect database all the logic written here (MongoDB, PostgresSQL), middlewares->(to run the code in between for example to check in the between when you get the request from the server eg you get request  when you were asking to server now using middlewares in middle to get the cookies so that if you are capable of using that infomation ), models , routes-('/', '/instagram') we use separate folder for that cus in production its gonna be huge , utils->(utilities) you need a lots of utilities like file upload is one utility, like for mailing, like for taking and giving tokens those things that are being repeat why not to to create a file folder and use it and that is called utilities,  all the professional grade project you get this Utils 

11. Prettier -> Its a plugin (mostly said it is a VS code extention use that one) but when you are writing professional grade code you don't write alone, you write with other memeber as well so for eg. if somone used semicomma and someone didn't in JS then when you mergin in the git there would be lots of conflict so team need to be in a same phase which spacing are we using two spacing or four spacing (Tap) this communication is needed, also like if one has two spacing and the other have four spacing there would be crazy amount of conflict working in the same file so use Prettier setting per project basic so we install prettier, 

It is also a Dev dependency majorly so we do npm i -D prettier instead of just npm i prettier for dependency and you need to add two three file manaully  one is (.prettierrc) and rc at last 
{
    "sigleQuote": false,
    "bracketSpacing": true,
    "tablWidth": 2,
    "trailingComma": "es5",
    "semi": true
} 

another one is .prettierignore (in which files not to implement prettier) like /.vscode
/node_modules
./dist

*.env
.env
.env.*

====================================================================================================================
                                          How to connect database in MERN 

12. MongoDB Atlas (gives online Database), In MongoDB we use moslty Network Access and Database Access 

13. In MongoDB Atlas you need two things : a. IP address allow so that you can access  and b. correct ID, Password and ofcourse URL  and go to datbase or overview and connect 

14. In professional settings, when you add an Ip address, it typically done for a specific machine where the backend code is hosted. In production-grade settings, you avoid allowing acess from anywhere for security reasons. In some cases, for testing or if we need to check something, we temporarily allow certain Ips for 6hours or 10 hours.

15. Connecting to Dabatabse take the URL from the overview -> connect-> compass  and  remove the / at the end while putting in .env also PORT="Number"

16. Need to have a name of Database so in Constants we kept export const DB_Name - "videotube"

                                            Two approach to connect database
1. One approach is that we put all the code inside the index file because we are going to execute the index file 1st through node . So we can put all the code inside the index file and as soon as my index file loads, the function where we have written all the database connection code will execute immediately.

2.The second approach is to create a folder named "DB" where the database connection function inside it and then import that function into the index file and execute it there.Both approaches have their pros and cons. If you write the code separately, the code will be clean, well distributed and modular, which is better professional approach. But if you want, you can also put everything inside the index file.

17. App.js will be through express and Database Connection will be through mongoose.We also need npm package of .env(dotenv), mongoose and express 
connecting Mongoose with database - mongoose.connect('mongodb://127.0.0.1:27017/myapp');  instead of local host we will give alas URL 


                                                 Database 
                                REMEMEBER TWO THINGS ((Try Catch and async await ))
The first thing is that whenever you try to interact with database, problems can arise. This means you should wrap it in try catch  block which is much better approach. Now whether you use try catch or promises both can handle errors because errors are handled there as well using resolve and reject. So you must use one of the two. 

The second thing is that the database is always in another continent. This means that database interaction take time so using a async await is necessary. It is always a better approach to wrap database interactions in try catch and ensure proper handling with a async await.  

18. Never connect DB in one line, also remember try putting ; in IIFE ;()() for cleaning purpose also  Mongoose give return object

Database server for production, development Testing are Different in each 

dotenvironemnt .env -> As early as possible in your application, import and configure dotenv:This is an environment variable what we need is as soon as our applicaiton load at the same time all the environment variable should be available if it is available in the main file then all will get accesss, so the first file which load which is index.js in the same file we load environment variable

using experimental feautres 
as import 'dotenv/config' in not in used much so what we can do is in the package.json in script what you can do is scripts : "dev": 'nodemon -r dotenv/config --experimental-json-modules src/index.js' why we doing to make it consistent: maybe no need --experimental-json-modules  it ealier version it needed to make consistent.

import dotenv from "dotenv"
import connectDB from "./db";

dotenv.config({
    path: './env'
})

when you you change something in .env you have to restart the server nodemon doesn't help there

=====================================================================================================================
                                        EXPRESS-> https://expressjs.com/en/5x/api.html

19.  Mostly you will be in API reference, and there are two main that you gonna use it which is REQUEST AND RESPONSE

a.Request -
 it s an object that contains all the details of an incoming HTTP request send by a client (browser,Postman, frontend app, etc). It includes infomation like the method(GET, POST,etc), URL, query parameters(?search=express), route parameters (/users/:id), body data (sent in POST requests), and headers (like authentication tokens). The server reads this data to understand what the client wants and responds accordingly. For example, in a login form, req.body helps retrieve the username and password submitted by the user. Without req, the server wouldn’t know what the client is requesting

  req.params ->(whenever the request comes from URL it comes from req.params)where params means parameters  like /users/:id, "/products/:category/:id

 req.body ->req.body holds the data sent by the client in the body of the request, It’s essential for handling data when the client sends data to the server, such as logging in, submitting a form, or uploading a file! 

 req.cookies -> Cookies are small pieces of data that the server can store in the client’s browser and send back with subsequent requests. They are often used for things like authentication (storing login sessions) or remembering user preferences. To work with cookies in Express, you typically use the cookie-parser middleware to parse the cookies and make them available in req.cookies. ->npm i cookies-parser

 CORS -CORS is a security feature that manages cross-origin requests between different domains.CORS ensures that only trusted websites can make requests to your server, preventing malicious activity from untrusted sources!
 npm i cors

 You use app.use(cors()0)// Global Middleware: You use app.use() when you want to apply the middleware to all incoming requests, regardless of the route.

 CORS_ORIGIN =*  here star mean from anywhere 

  Middleware
 Middleware in Express is like a helper function that runs between receiving a request and sending a response. It can modify, check, or handle the request before it reaches the final route handler.
Think of middleware as a checkpoint where you can: ✅ Process incoming requests (e.g., check if a user is logged in)

             (err, req, res, next) 
next → Calls the next middleware function in the stack.


b. Responds->
In Express.js, a response (res) is an object that allows the server to send data back to the client after processing a request. It can send plain text, JSON, HTML, status codes, or even redirect the client to another page. For example, res.send("Hello!") sends a simple text response, while res.json({ message: "Success" }) sends JSON data. The response also includes status codes like res.status(404).send("Not Found") to indicate errors. Without res, the client wouldn’t receive any output from the server, making it essential for communication between the backend and frontend! 


20. Utility ->In backend development, the utils (short for utilities) folder is used to store helper functions, reusable modules, and utility scripts that are not tied to a specific route or database model. These functions simplify code, promote reusability, and keep the project organized.


                               To control error 
21 Nodejs api error -https://nodejs.org/api/errors.html#class-error

22. Server Status Code 
Informational responses (100 – 199)
Successful responses (200 – 299)
Redirection messages (300 – 399)
Client error responses (400 – 499)
Server error responses (500 – 599)

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
 23                                           Working with models
                                    
mongoose-aggregate-paginate-v2
https://www.mongodb.com/docs/manual/core/aggregation-pipeline/


bcrpt - A bcrypt library for Nodejs
bcrptjs- Optimized bcrypt in plain js with zero dependencies. Compatible to 'bcrypt' 

bcrypt is a password hashing library used to securely store passwords in a database. Instead of saving raw passwords (which is very unsafe), bcrypt converts passwords into an unreadable format (hash), making them difficult for attackers to crack.

Token key - jsonwebtoken -npm i jsonwebtoken  -Used for secure login, user authorization, and API security. -> 

A Bearer Token in JWT is like a digital key that allows a user to access protected resources (APIs, routes, etc.). It is included in the Authorization header when making requests to the serve
The word "Bearer" means whoever holds this token has access. If someone has your token, they can use it to access protected resources without needing a username & password.


                                Middleware pre hook 
Just before your data save, you can use this pre hook so as to make your password encrypt 

SHA256-HA-256 (Secure Hash Algorithm 256-bit) is a cryptographic hash function that converts input data into a 256-bit (32-byte) fixed-length hash. It is widely used for data integrity, password hashing, digital signatures, and blockchain security.


/////////////////////////////////////////////////////////////////////////////////////////////////////////
24                              Cloudinary - for uploading file and images and many more
                              npm i Cloudinary

Two packages needed for uploading files in the backend 
1. express-fileupload -http://npmjs.com/package/express-fileupload
2. Multer -npm i multer (mosstly used )

 a two-step strategy for file uploads in a production environment: first, temporarily saving the file on the backend server and then uploading it to Cloudinary.
Here's what the transcript says about this process:
•
User Upload via Multer: When a user uploads a file, the backend uses Multer middleware to receive the file and save it temporarily on the local server's file system.
•
Temporary Local Storage: This temporary storage is achieved using Multer's disk storage engine, which allows specifying a destination folder (e.g., public/temp/) on the server to save the incoming file.
•
Rationale for the Two-Step Approach: The primary reason for this two-step process is to enhance resilience and provide an opportunity for retries. If the subsequent upload to Cloudinary fails for any reason, the file is already present on the server, making it possible to attempt the upload again. This is described as a common practice in production-grade server


Cloudinary Upload: After the file is temporarily saved on the server, the backend then uses the Cloudinary SDK to take the local file path and upload the file to the Cloudinary service. The uploadOnCloudinary utility function is designed to handle this step.
•
Local File Removal: After a successful (or even failed) attempt to upload to Cloudinary, the transcript emphasizes the importance of deleting the temporarily saved file from the local server using Node.js's fs.unlinkSync() method. This prevents the accumulation of potentially corrupted or unnecessary files on the server's disk. fs -> file system helps  where you can read write delete and update 

Alternative: Direct Upload: The transcript acknowledges that it is technically possible to directly upload the file from Multer to Cloudinary without the intermediate local storage step. However, it notes that the two-step approach is more common in production settings for the reasons mentioned above

By using multer we gonna creat Middleware - for registration 

